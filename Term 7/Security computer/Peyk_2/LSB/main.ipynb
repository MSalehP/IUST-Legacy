{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSB statistical analysis #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Temples_000044.png: index 1 is out of bounds for axis 0 with size 1\n",
      "Results saved to results.csv\n",
      "\n",
      "Summary:\n",
      "Total Images: 861\n",
      "Clean Images: 570 (66.20%)\n",
      "Steganography Detected Images: 291 (33.80%)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import csv\n",
    "\n",
    "def extract_lsb(image):\n",
    "    \"\"\"\n",
    "    استخراج بیت کم ارزش (LSB) از تصویر.\n",
    "    \"\"\"\n",
    "    return image & 1\n",
    "\n",
    "def calculate_statistical_features(lsb):\n",
    "    \"\"\"\n",
    "    محاسبه ویژگی‌های آماری از LSB.\n",
    "    \"\"\"\n",
    "    mean = np.mean(lsb)  # میانگین بیت‌های LSB\n",
    "    std_dev = np.std(lsb)  # انحراف معیار بیت‌های LSB\n",
    "    unique, counts = np.unique(lsb, return_counts=True)\n",
    "    bit_balance = counts[0] / (counts[1] + 1e-9)  # نسبت بیت‌های 0 به 1\n",
    "    return mean, std_dev, bit_balance\n",
    "\n",
    "def detect_steganography(image_path):\n",
    "    \"\"\"\n",
    "    بررسی اینکه آیا تصویر آلوده است یا پاک.\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Unable to read image: {image_path}\")\n",
    "    \n",
    "    lsb = extract_lsb(image)\n",
    "    mean, std_dev, bit_balance = calculate_statistical_features(lsb)\n",
    "    \n",
    "    # معیارهای تشخیص\n",
    "    threshold_mean = 0.02\n",
    "    threshold_std = 0.05\n",
    "    threshold_balance = 1.1\n",
    "    \n",
    "    # بررسی ویژگی‌ها برای تشخیص\n",
    "    if abs(mean - 0.5) > threshold_mean or std_dev < threshold_std or bit_balance > threshold_balance:\n",
    "        return \"Steganography Detected\"\n",
    "    else:\n",
    "        return \"Clean\"\n",
    "\n",
    "def process_folder(input_folder, output_csv):\n",
    "    \"\"\"\n",
    "    پردازش تمام تصاویر در یک پوشه و ذخیره نتایج در فایل CSV.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    clean_count = 0\n",
    "    stego_count = 0\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        if not os.path.isfile(image_path):\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            status = detect_steganography(image_path)\n",
    "            results.append((filename, status))\n",
    "            if status == \"Clean\":\n",
    "                clean_count += 1\n",
    "            else:\n",
    "                stego_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "    \n",
    "    # ذخیره نتایج در فایل CSV\n",
    "    with open(output_csv, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Image\", \"Status\"])\n",
    "        writer.writerows(results)\n",
    "    print(f\"Results saved to {output_csv}\")\n",
    "\n",
    "    # چاپ آماری\n",
    "    total_images = clean_count + stego_count\n",
    "    clean_percentage = (clean_count / total_images) * 100 if total_images > 0 else 0\n",
    "    stego_percentage = (stego_count / total_images) * 100 if total_images > 0 else 0\n",
    "\n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"Total Images: {total_images}\")\n",
    "    print(f\"Clean Images: {clean_count} ({clean_percentage:.2f}%)\")\n",
    "    print(f\"Steganography Detected Images: {stego_count} ({stego_percentage:.2f}%)\")\n",
    "\n",
    "# اجرای کد برای پوشه نمونه\n",
    "input_folder = \"./10000_random_files/\"  # مسیر پوشه ورودی\n",
    "output_csv = \"results.csv\"  # فایل خروجی\n",
    "process_folder(input_folder, output_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def embed_message(image, message):\n",
    "    \"\"\"\n",
    "    جاسازی پیام در تصویر با استفاده از LSB.\n",
    "    \"\"\"\n",
    "    binary_message = ''.join(format(ord(char), '08b') for char in message)\n",
    "    flat_image = image.flatten()\n",
    "    for i in range(len(binary_message)):\n",
    "        flat_image[i] = (flat_image[i] & ~1) | int(binary_message[i])\n",
    "    return flat_image.reshape(image.shape)\n",
    "\n",
    "def generate_dataset(clean_folder, output_folder, message=\"Hidden Message\"):\n",
    "    \"\"\"\n",
    "    ایجاد داده‌های برچسب‌گذاری‌شده با جاسازی پیام‌ها در تصاویر.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    for i, filename in enumerate(os.listdir(clean_folder)):\n",
    "        image_path = os.path.join(clean_folder, filename)\n",
    "        if filename.endswith(\".png\") or filename.endswith(\".jpg\"):\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            # ذخیره تصویر پاک\n",
    "            cv2.imwrite(os.path.join(output_folder, f\"clean_{i}.png\"), image)\n",
    "            # ایجاد و ذخیره تصویر آلوده\n",
    "            stego_image = embed_message(image, message)\n",
    "            cv2.imwrite(os.path.join(output_folder, f\"stego_{i}.png\"), stego_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image):\n",
    "    \"\"\"\n",
    "    استخراج ویژگی‌ها از تصویر.\n",
    "    \"\"\"\n",
    "    lsb = image & 1\n",
    "    mean_lsb = np.mean(lsb)\n",
    "    std_lsb = np.std(lsb)\n",
    "    zeros, ones = np.unique(lsb, return_counts=True)[1]\n",
    "    balance_ratio = zeros / (zeros + ones)\n",
    "    return [mean_lsb, std_lsb, balance_ratio]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "def train_ml_model(feature_csv):\n",
    "    \"\"\"\n",
    "    آموزش مدل ماشین لرنینگ.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(feature_csv)\n",
    "    X = data[[\"mean_lsb\", \"std_lsb\", \"balance_ratio\"]].values\n",
    "    y = data[\"label\"].values  # 0 برای پاک، 1 برای آلوده\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    return clf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency Analysis #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_lsb_distribution(image):\n",
    "    \"\"\"\n",
    "    تحلیل فراوانی بیت‌ها در تصویر.\n",
    "    \"\"\"\n",
    "    lsb = image & 1\n",
    "    unique, counts = np.unique(lsb, return_counts=True)\n",
    "    zeros = counts[0] if 0 in unique else 0\n",
    "    ones = counts[1] if 1 in unique else 0\n",
    "    balance_ratio = zeros / (zeros + ones)\n",
    "    return balance_ratio, zeros, ones\n",
    "\n",
    "def detect_with_distribution(image):\n",
    "    \"\"\"\n",
    "    تشخیص پاک یا آلوده بودن با تحلیل فراوانی بیت‌ها.\n",
    "    \"\"\"\n",
    "    balance_ratio, zeros, ones = analyze_lsb_distribution(image)\n",
    "    if abs(balance_ratio - 0.5) > 0.1:\n",
    "        return \"Steganography Detected\"\n",
    "    else:\n",
    "        return \"Clean\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_results(image, clf):\n",
    "    \"\"\"\n",
    "    ترکیب نتایج سه روش.\n",
    "    \"\"\"\n",
    "    # روش اول: آماری\n",
    "    lsb = image & 1\n",
    "    mean_lsb = np.mean(lsb)\n",
    "    std_lsb = np.std(lsb)\n",
    "\n",
    "    # روش سوم: تحلیل فراوانی\n",
    "    balance_ratio, _, _ = analyze_lsb_distribution(image)\n",
    "\n",
    "    # روش دوم: ماشین لرنینگ\n",
    "    features = np.array([[mean_lsb, std_lsb, balance_ratio]])\n",
    "    ml_result = clf.predict(features)[0]\n",
    "\n",
    "    # ترکیب نتایج\n",
    "    results = [\n",
    "        \"Steganography Detected\" if abs(mean_lsb - 0.5) > 0.05 else \"Clean\",\n",
    "        \"Steganography Detected\" if abs(balance_ratio - 0.5) > 0.1 else \"Clean\",\n",
    "        \"Steganography Detected\" if ml_result == 1 else \"Clean\",\n",
    "    ]\n",
    "\n",
    "    final_result = (\n",
    "        \"Steganography Detected\"\n",
    "        if results.count(\"Steganography Detected\") > 1\n",
    "        else \"Clean\"\n",
    "    )\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "Total Images: 1029\n",
      "Clean Images: 774 (75.22%)\n",
      "Steganography Detected Images: 255 (24.78%)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import csv\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# روش اول: محاسبه ویژگی‌های آماری\n",
    "def extract_lsb(image):\n",
    "    return image & 1\n",
    "\n",
    "def calculate_statistical_features(lsb):\n",
    "    mean = np.mean(lsb)\n",
    "    std_dev = np.std(lsb)\n",
    "    unique, counts = np.unique(lsb, return_counts=True)\n",
    "    bit_balance = counts[0] / (counts[1] + 1e-9) if len(counts) > 1 else 0\n",
    "    return mean, std_dev, bit_balance\n",
    "\n",
    "def detect_statistical(image):\n",
    "    lsb = extract_lsb(image)\n",
    "    mean, std_dev, bit_balance = calculate_statistical_features(lsb)\n",
    "    threshold_mean = 0.02\n",
    "    threshold_std = 0.05\n",
    "    threshold_balance = 1.1\n",
    "    if abs(mean - 0.5) > threshold_mean or std_dev < threshold_std or bit_balance > threshold_balance:\n",
    "        return \"Steganography Detected\"\n",
    "    return \"Clean\"\n",
    "\n",
    "# روش دوم: ماشین لرنینگ\n",
    "def train_dummy_ml_model():\n",
    "    \"\"\"\n",
    "    آموزش یک مدل ساده با داده‌های مصنوعی.\n",
    "    \"\"\"\n",
    "    # داده‌های ساختگی برای آموزش\n",
    "    np.random.seed(42)\n",
    "    X = np.random.rand(1000, 3)\n",
    "    y = (X[:, 0] > 0.5).astype(int)  # مقدار فرضی\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X, y)\n",
    "    return clf\n",
    "\n",
    "def detect_with_ml(image, clf):\n",
    "    lsb = extract_lsb(image)\n",
    "    mean, std_dev, bit_balance = calculate_statistical_features(lsb)\n",
    "    features = np.array([[mean, std_dev, bit_balance]])\n",
    "    prediction = clf.predict(features)[0]\n",
    "    return \"Steganography Detected\" if prediction == 1 else \"Clean\"\n",
    "\n",
    "# روش سوم: تحلیل توزیع بیت‌ها\n",
    "def analyze_lsb_distribution(image):\n",
    "    lsb = image & 1\n",
    "    unique, counts = np.unique(lsb, return_counts=True)\n",
    "    zeros = counts[0] if 0 in unique else 0\n",
    "    ones = counts[1] if 1 in unique else 0\n",
    "    balance_ratio = zeros / (zeros + ones + 1e-9)\n",
    "    return balance_ratio, zeros, ones\n",
    "\n",
    "def detect_with_distribution(image):\n",
    "    balance_ratio, _, _ = analyze_lsb_distribution(image)\n",
    "    if abs(balance_ratio - 0.5) > 0.1:\n",
    "        return \"Steganography Detected\"\n",
    "    return \"Clean\"\n",
    "\n",
    "# ترکیب نتایج سه روش\n",
    "def combine_results(stat_result, ml_result, dist_result):\n",
    "    results = [stat_result, ml_result, dist_result]\n",
    "    return \"Steganography Detected\" if results.count(\"Steganography Detected\") > 1 else \"Clean\"\n",
    "\n",
    "# پردازش پوشه تصاویر\n",
    "def process_folder(input_folder, output_csv):\n",
    "    results = []\n",
    "    clean_count = 0\n",
    "    stego_count = 0\n",
    "    clf = train_dummy_ml_model()  # آموزش مدل\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        if not os.path.isfile(image_path):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if image is None:\n",
    "                raise ValueError(f\"Unable to read image: {filename}\")\n",
    "\n",
    "            # اجرای سه روش\n",
    "            stat_result = detect_statistical(image)\n",
    "            ml_result = detect_with_ml(image, clf)\n",
    "            dist_result = detect_with_distribution(image)\n",
    "\n",
    "            # ترکیب نتایج\n",
    "            final_result = combine_results(stat_result, ml_result, dist_result)\n",
    "\n",
    "            results.append([filename, stat_result, ml_result, dist_result, final_result])\n",
    "            if final_result == \"Clean\":\n",
    "                clean_count += 1\n",
    "            else:\n",
    "                stego_count += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "    # ذخیره نتایج در CSV\n",
    "    with open(output_csv, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Image\", \"Statistical Result\", \"ML Result\", \"Distribution Result\", \"Final Result\"])\n",
    "        writer.writerows(results)\n",
    "\n",
    "    # چاپ آماری\n",
    "    total_images = clean_count + stego_count\n",
    "    clean_percentage = (clean_count / total_images) * 100 if total_images > 0 else 0\n",
    "    stego_percentage = (stego_count / total_images) * 100 if total_images > 0 else 0\n",
    "\n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"Total Images: {total_images}\")\n",
    "    print(f\"Clean Images: {clean_count} ({clean_percentage:.2f}%)\")\n",
    "    print(f\"Steganography Detected Images: {stego_count} ({stego_percentage:.2f}%)\")\n",
    "\n",
    "# اجرای کد\n",
    "input_folder = \"./10000_random_files/\"\n",
    "output_csv = \"results.csv\"\n",
    "process_folder(input_folder, output_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stego Maker #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved clean image: ./output_clean/Antique shops_000008.jpg\n",
      "Saved clean image: ./output_clean/Birds_000012.jpg\n",
      "Saved clean image: ./output_clean/Beauty_000026.jpg\n",
      "Saved clean image: ./output_clean/Barbecue_000014.jpg\n",
      "Saved clean image: ./output_clean/Architecture photography_000027.jpg\n",
      "Saved clean image: ./output_clean/Breakfast_000006.jpg\n",
      "Saved clean image: ./output_clean/Art exhibitions_000008.jpg\n",
      "Saved clean image: ./output_clean/Baseball_000006.jpg\n",
      "Saved clean image: ./output_clean/Balcony gardens_000017.jpg\n",
      "Saved clean image: ./output_clean/Black and white photography_000026.jpg\n",
      "Saved clean image: ./output_clean/Beer_000039.jpg\n",
      "Saved clean image: ./output_clean/Animal rights_000029.jpg\n",
      "Saved clean image: ./output_clean/Art exhibitions_000011.jpg\n",
      "Saved clean image: ./output_clean/Accessories_000025.jpg\n",
      "Saved clean image: ./output_clean/Beaches_000028.jpg\n",
      "Saved clean image: ./output_clean/Abstract art_000038.jpg\n",
      "Saved clean image: ./output_clean/Bookstores_000003.jpg\n",
      "Saved clean image: ./output_clean/Beverages_000004.jpg\n",
      "Saved clean image: ./output_clean/Business tips_000001.png\n",
      "Saved clean image: ./output_clean/Brewery tours_000030.jpg\n",
      "Saved clean image: ./output_clean/Art_000010.png\n",
      "Saved clean image: ./output_clean/Breakfast_000028.jpg\n",
      "Saved clean image: ./output_clean/Antique shops_000029.jpg\n",
      "Saved clean image: ./output_clean/AI technology_000005.jpg\n",
      "Saved clean image: ./output_clean/Architecture_000004.jpg\n",
      "Saved clean image: ./output_clean/App reviews_000007.png\n",
      "Saved clean image: ./output_clean/Balcony gardens_000028.jpg\n",
      "Saved clean image: ./output_clean/Beach_000002.jpg\n",
      "Saved clean image: ./output_clean/Bread_000018.jpg\n",
      "Saved clean image: ./output_clean/Beverages_000001.jpg\n",
      "Saved clean image: ./output_clean/Abstract art_000002.jpg\n",
      "Saved clean image: ./output_clean/Bread_000008.jpg\n",
      "Saved clean image: ./output_clean/App reviews_000016.png\n",
      "Saved clean image: ./output_clean/Barbecue_000030.jpg\n",
      "Saved clean image: ./output_clean/Accessories_000036.jpg\n",
      "Saved clean image: ./output_clean/Accessories_000065.jpg\n",
      "Saved clean image: ./output_clean/Art supplies_000019.png\n",
      "Saved clean image: ./output_clean/Architecture_000019.jpg\n",
      "Saved clean image: ./output_clean/Beauty tutorials_000018.jpg\n",
      "Saved clean image: ./output_clean/Accessories_000049.jpg\n",
      "Saved clean image: ./output_clean/Basketball_000005.png\n",
      "Saved clean image: ./output_clean/Barbecue_000008.jpg\n",
      "Saved clean image: ./output_clean/Beer_000030.jpg\n",
      "Saved clean image: ./output_clean/Animal rights_000030.jpg\n",
      "Saved clean image: ./output_clean/Affiliate marketing_000020.png\n",
      "Saved clean image: ./output_clean/Bakeries_000012.jpg\n",
      "Saved clean image: ./output_clean/Accessories_000031.jpg\n",
      "Saved clean image: ./output_clean/Augmented reality_000022.jpg\n",
      "Saved clean image: ./output_clean/Art galleries_000022.jpg\n",
      "Saved clean image: ./output_clean/Accessories_000044.jpg\n",
      "Saved stego image: ./output_stego/Bookstores_000002.jpg\n",
      "Saved stego image: ./output_stego/Abstract_000004.jpg\n",
      "Saved stego image: ./output_stego/Barbecue_000035.jpg\n",
      "Saved stego image: ./output_stego/Ballet_000011.jpg\n",
      "Saved stego image: ./output_stego/Animal rights_000007.jpg\n",
      "Saved stego image: ./output_stego/Beauty_000001.jpg\n",
      "Saved stego image: ./output_stego/Architecture photography_000012.jpg\n",
      "Saved stego image: ./output_stego/Black and white photography_000041.jpg\n",
      "Saved stego image: ./output_stego/Black and white photography_000035.jpg\n",
      "Saved stego image: ./output_stego/Beauty tutorials_000004.jpg\n",
      "Saved stego image: ./output_stego/Bears_000002.jpg\n",
      "Saved stego image: ./output_stego/Abstract art_000007.jpg\n",
      "Saved stego image: ./output_stego/Beaches_000016.jpg\n",
      "Saved stego image: ./output_stego/Accessories_000063.jpg\n",
      "Saved stego image: ./output_stego/Blogging_000012.png\n",
      "Saved stego image: ./output_stego/Accessories_000028.jpg\n",
      "Saved stego image: ./output_stego/Art exhibitions_000013.jpg\n",
      "Saved stego image: ./output_stego/Art exhibitions_000002.jpg\n",
      "Saved stego image: ./output_stego/Accessories_000040.jpg\n",
      "Saved stego image: ./output_stego/Accessories_000045.jpg\n",
      "Saved stego image: ./output_stego/Beverages_000008.png\n",
      "Saved stego image: ./output_stego/App reviews_000006.png\n",
      "Saved stego image: ./output_stego/Bakeries_000014.jpg\n",
      "Saved stego image: ./output_stego/Basketball_000020.jpg\n",
      "Saved stego image: ./output_stego/Barbecue_000051.jpg\n",
      "Saved stego image: ./output_stego/Art and culture_000019.png\n",
      "Saved stego image: ./output_stego/Brewery tours_000005.jpg\n",
      "Saved stego image: ./output_stego/Artisan crafts_000019.jpg\n",
      "Saved stego image: ./output_stego/Bakeries_000003.jpg\n",
      "Saved stego image: ./output_stego/Abstract_000011.jpg\n",
      "Saved stego image: ./output_stego/Breakfast_000029.jpg\n",
      "Saved stego image: ./output_stego/Basketball_000013.png\n",
      "Saved stego image: ./output_stego/Augmented reality_000015.jpg\n",
      "Saved stego image: ./output_stego/Bakeries_000005.jpg\n",
      "Saved stego image: ./output_stego/Antique shops_000028.jpg\n",
      "Saved stego image: ./output_stego/Blogging_000015.png\n",
      "Saved stego image: ./output_stego/Bread_000038.png\n",
      "Saved stego image: ./output_stego/Abstract art_000013.jpg\n",
      "Saved stego image: ./output_stego/Beauty tutorials_000012.jpg\n",
      "Saved stego image: ./output_stego/App reviews_000022.png\n",
      "Saved stego image: ./output_stego/Beaches_000002.jpg\n",
      "Saved stego image: ./output_stego/Accessories_000017.jpg\n",
      "Saved stego image: ./output_stego/Animal rights_000002.jpg\n",
      "Saved stego image: ./output_stego/Abstract art_000005.jpg\n",
      "Saved stego image: ./output_stego/Augmented reality_000026.jpg\n",
      "Saved stego image: ./output_stego/Bears_000015.jpg\n",
      "Saved stego image: ./output_stego/Beverages_000017.jpg\n",
      "Saved stego image: ./output_stego/Aerial photography_000022.jpg\n",
      "Saved stego image: ./output_stego/Beer_000044.jpg\n",
      "Saved stego image: ./output_stego/Architecture photography_000015.jpg\n",
      "\n",
      "Processing complete.\n",
      "Clean images saved: 50\n",
      "Stego images saved: 50\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import string\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def generate_random_text(length=100):\n",
    "    \"\"\"\n",
    "    تولید یک متن تصادفی با استفاده از حروف الفبا و اعداد.\n",
    "    \"\"\"\n",
    "    characters = string.ascii_letters + string.digits + string.punctuation + ' '  # مجموعه کاراکترها\n",
    "    random_text = ''.join(random.choice(characters) for _ in range(length))  # تولید متن تصادفی\n",
    "    return random_text\n",
    "\n",
    "def text_to_binary(text):\n",
    "    \"\"\"\n",
    "    تبدیل متن به رشته باینری.\n",
    "    \"\"\"\n",
    "    return ''.join(format(ord(c), '08b') for c in text)  # تبدیل هر کاراکتر به کد ASCII و سپس باینری\n",
    "\n",
    "def embed_message(image, message):\n",
    "    \"\"\"\n",
    "    نهان‌نگاری پیام در تصویر با استفاده از LSB.\n",
    "    \"\"\"\n",
    "    # تبدیل تصویر به آرایه یک‌بعدی\n",
    "    flattened_image = image.flatten()\n",
    "    \n",
    "    # بررسی ظرفیت\n",
    "    if len(message) > len(flattened_image):\n",
    "        raise ValueError(\"Message is too long for the image capacity.\")\n",
    "    \n",
    "    # جاسازی بیت‌ها در LSB\n",
    "    for i in range(len(message)):\n",
    "        flattened_image[i] = (flattened_image[i] & ~1) | int(message[i])  # جایگذاری LSB\n",
    "    \n",
    "    # بازگرداندن آرایه به شکل تصویر اصلی\n",
    "    embedded_image = flattened_image.reshape(image.shape)\n",
    "    return embedded_image\n",
    "\n",
    "def process_images(input_folder, clean_output_folder, stego_output_folder, num_clean, num_stego, usage_percent=0.8):\n",
    "    \"\"\"\n",
    "    پردازش تصاویر:\n",
    "    - تعدادی تصویر را بدون تغییر در پوشه Clean ذخیره می‌کند.\n",
    "    - تعدادی تصویر را آلوده کرده و در پوشه Stego ذخیره می‌کند.\n",
    "    \"\"\"\n",
    "    # دریافت لیست تصاویر\n",
    "    images = [f for f in os.listdir(input_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]\n",
    "    if len(images) < num_clean + num_stego:\n",
    "        raise ValueError(\"Not enough images in the input folder to satisfy the request.\")\n",
    "\n",
    "    # انتخاب تصاویر به صورت تصادفی\n",
    "    selected_images = random.sample(images, num_clean + num_stego)\n",
    "    clean_images = selected_images[:num_clean]\n",
    "    stego_images = selected_images[num_clean:]\n",
    "\n",
    "    # ایجاد پوشه‌ها در صورت نیاز\n",
    "    os.makedirs(clean_output_folder, exist_ok=True)\n",
    "    os.makedirs(stego_output_folder, exist_ok=True)\n",
    "\n",
    "    # ذخیره تصاویر پاک\n",
    "    for filename in clean_images:\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if image is None:\n",
    "            print(f\"Skipping invalid image: {filename}\")\n",
    "            continue\n",
    "        output_path = os.path.join(clean_output_folder, filename)\n",
    "        cv2.imwrite(output_path, image)\n",
    "        print(f\"Saved clean image: {output_path}\")\n",
    "\n",
    "    # ذخیره تصاویر آلوده\n",
    "    for filename in stego_images:\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if image is None:\n",
    "            print(f\"Skipping invalid image: {filename}\")\n",
    "            continue\n",
    "        \n",
    "        # ظرفیت تصویر\n",
    "        capacity = image.shape[0] * image.shape[1]\n",
    "        \n",
    "        # تولید متن تصادفی\n",
    "        random_text = generate_random_text(length=100)  # طول متن تصادفی\n",
    "        message = text_to_binary(random_text)  # تبدیل متن به باینری\n",
    "        \n",
    "        # نهان‌نگاری پیام\n",
    "        stego_image = embed_message(image, message)\n",
    "        output_path = os.path.join(stego_output_folder, filename)\n",
    "        cv2.imwrite(output_path, stego_image)\n",
    "        print(f\"Saved stego image: {output_path}\")\n",
    "\n",
    "    print(\"\\nProcessing complete.\")\n",
    "    print(f\"Clean images saved: {num_clean}\")\n",
    "    print(f\"Stego images saved: {num_stego}\")\n",
    "\n",
    "# مسیرها و تعداد تصاویر\n",
    "input_folder = \"./10000_random_files/\"  # مسیر فولدر تصاویر پاک\n",
    "clean_output_folder = \"./output_clean/\"  # مسیر ذخیره تصاویر پاک\n",
    "stego_output_folder = \"./output_stego/\"  # مسیر ذخیره تصاویر آلوده\n",
    "num_clean = 50  # تعداد تصاویر پاک\n",
    "num_stego = 50  # تعداد تصاویر آلوده\n",
    "\n",
    "# اجرای کد\n",
    "process_images(input_folder, clean_output_folder, stego_output_folder, num_clean, num_stego)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# روش آماری #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to detection_results.csv\n",
      "\n",
      "Summary:\n",
      "Total Images: 1000\n",
      "Clean Images: 752 (75.20%)\n",
      "Stego Images: 248 (24.80%)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def extract_lsb(image):\n",
    "    \"\"\"\n",
    "    استخراج بیت‌های کم ارزش (LSB) از تصویر.\n",
    "    \"\"\"\n",
    "    return image & 1\n",
    "\n",
    "def calculate_statistical_features(lsb):\n",
    "    \"\"\"\n",
    "    محاسبه ویژگی‌های آماری از LSB.\n",
    "    \"\"\"\n",
    "    mean = np.mean(lsb)  # میانگین بیت‌های LSB\n",
    "    std_dev = np.std(lsb)  # انحراف معیار بیت‌های LSB\n",
    "    unique, counts = np.unique(lsb, return_counts=True)\n",
    "    bit_balance = counts[0] / (counts[1] + 1e-9)  # نسبت بیت‌های 0 به 1\n",
    "    return mean, std_dev, bit_balance\n",
    "\n",
    "def detect_steganography(image_path):\n",
    "    \"\"\"\n",
    "    تشخیص اینکه آیا تصویر آلوده است یا پاک.\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Unable to read image: {image_path}\")\n",
    "    \n",
    "    lsb = extract_lsb(image)\n",
    "    mean, std_dev, bit_balance = calculate_statistical_features(lsb)\n",
    "    \n",
    "    # معیارهای تشخیص\n",
    "    threshold_mean = 0.02\n",
    "    threshold_std = 0.05\n",
    "    threshold_balance = 1.1\n",
    "    \n",
    "    # بررسی ویژگی‌ها برای تشخیص\n",
    "    if abs(mean - 0.5) > threshold_mean or std_dev < threshold_std or bit_balance > threshold_balance:\n",
    "        return \"Stego\"\n",
    "    else:\n",
    "        return \"Clean\"\n",
    "\n",
    "def process_images_and_save_results(input_folder, output_csv):\n",
    "    \"\"\"\n",
    "    پردازش تصاویر برای تشخیص پاک یا آلوده بودن و ذخیره نتایج در فایل CSV.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    clean_count = 0\n",
    "    stego_count = 0\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        if not os.path.isfile(image_path):\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            status = detect_steganography(image_path)\n",
    "            results.append((filename, status))\n",
    "            if status == \"Clean\":\n",
    "                clean_count += 1\n",
    "            else:\n",
    "                stego_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "    \n",
    "    # ذخیره نتایج در فایل CSV\n",
    "    with open(output_csv, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Image\", \"Status\"])\n",
    "        writer.writerows(results)\n",
    "    print(f\"Results saved to {output_csv}\")\n",
    "\n",
    "    # چاپ آماری\n",
    "    total_images = clean_count + stego_count\n",
    "    clean_percentage = (clean_count / total_images) * 100 if total_images > 0 else 0\n",
    "    stego_percentage = (stego_count / total_images) * 100 if total_images > 0 else 0\n",
    "\n",
    "    print(\"\\nSummary:\")\n",
    "    print(f\"Total Images: {total_images}\")\n",
    "    print(f\"Clean Images: {clean_count} ({clean_percentage:.2f}%)\")\n",
    "    print(f\"Stego Images: {stego_count} ({stego_percentage:.2f}%)\")\n",
    "\n",
    "# مسیر و فایل خروجی\n",
    "input_folder = \"./combined_images/\"  # مسیر فولدر تصاویر\n",
    "output_csv = \"detection_results.csv\"  # فایل خروجی CSV\n",
    "\n",
    "# اجرای کد\n",
    "process_images_and_save_results(input_folder, output_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# غیر هوش مصنوعی #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "Total Images: 98\n",
      "Clean Images: 752 (767.35%)\n",
      "Steganography Detected Images: 248 (253.06%)\n",
      "Correct Predictions: 44 (44.90%)\n",
      "Results saved to final_results.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import csv\n",
    "\n",
    "# استخراج بیت‌های کم ارزش (LSB)\n",
    "def extract_lsb(image):\n",
    "    return image & 1\n",
    "\n",
    "# محاسبه ویژگی‌های آماری\n",
    "def calculate_statistical_features(lsb):\n",
    "    mean = np.mean(lsb)  # میانگین بیت‌های LSB\n",
    "    std_dev = np.std(lsb)  # انحراف معیار بیت‌های LSB\n",
    "    unique, counts = np.unique(lsb, return_counts=True)\n",
    "    bit_balance = counts[0] / (counts[1] + 1e-9)  # نسبت بیت‌های 0 به 1\n",
    "    return mean, std_dev, bit_balance\n",
    "\n",
    "# محاسبه نسبت پیکسل‌های یکنواخت\n",
    "def uniform_pixel_ratio(lsb):\n",
    "    unique, counts = np.unique(lsb, return_counts=True)\n",
    "    return max(counts) / lsb.size  # نسبت پیکسل یکنواخت\n",
    "\n",
    "# تشخیص نهان‌نگاری بر اساس ویژگی‌ها\n",
    "def detect_steganography(features):\n",
    "    mean, std_dev, bit_balance, uniform_ratio = features\n",
    "    if abs(mean - 0.5) > 0.02 or std_dev < 0.05 or bit_balance > 1.1 or uniform_ratio > 0.55:\n",
    "        return \"Steganography Detected\"\n",
    "    else:\n",
    "        return \"Clean\"\n",
    "\n",
    "# مقایسه پیش‌بینی‌ها با برچسب واقعی (بر اساس مکان تصویر)\n",
    "def get_true_label(filename, clean_folder, stego_folder):\n",
    "    if filename in os.listdir(clean_folder):\n",
    "        return \"Clean\"\n",
    "    elif filename in os.listdir(stego_folder):\n",
    "        return \"Steganography Detected\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# پردازش تصاویر در یک پوشه\n",
    "def process_folder(input_folder, clean_folder, stego_folder, output_csv):\n",
    "    results = []\n",
    "    clean_count = 0\n",
    "    stego_count = 0\n",
    "    correct_count = 0\n",
    "    total_images = 0\n",
    "    \n",
    "    for filename in os.listdir(input_folder):\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if image is None:\n",
    "            continue\n",
    "        \n",
    "        # استخراج ویژگی‌ها\n",
    "        lsb = extract_lsb(image)\n",
    "        mean, std_dev, bit_balance = calculate_statistical_features(lsb)\n",
    "        uniform_ratio = uniform_pixel_ratio(lsb)\n",
    "        \n",
    "        # تشخیص آلودگی\n",
    "        features = [mean, std_dev, bit_balance, uniform_ratio]\n",
    "        predicted_status = detect_steganography(features)\n",
    "        \n",
    "        # گرفتن برچسب واقعی\n",
    "        true_label = get_true_label(filename, clean_folder, stego_folder)\n",
    "        \n",
    "        if true_label:\n",
    "            total_images += 1\n",
    "            if predicted_status == true_label:\n",
    "                correct_count += 1\n",
    "        \n",
    "        results.append((filename, predicted_status, true_label))\n",
    "        \n",
    "        # شمارش تعداد تصاویر\n",
    "        if predicted_status == \"Clean\":\n",
    "            clean_count += 1\n",
    "        else:\n",
    "            stego_count += 1\n",
    "    \n",
    "    # محاسبه دقت\n",
    "    accuracy = (correct_count / total_images) * 100 if total_images > 0 else 0\n",
    "    \n",
    "    # ذخیره نتایج در فایل CSV\n",
    "    with open(output_csv, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Image\", \"Predicted Status\", \"True Label\"])\n",
    "        writer.writerows(results)\n",
    "\n",
    "    # چاپ نتایج\n",
    "    clean_percentage = (clean_count / total_images) * 100 if total_images > 0 else 0\n",
    "    stego_percentage = (stego_count / total_images) * 100 if total_images > 0 else 0\n",
    "\n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"Total Images: {total_images}\")\n",
    "    print(f\"Clean Images: {clean_count} ({clean_percentage:.2f}%)\")\n",
    "    print(f\"Steganography Detected Images: {stego_count} ({stego_percentage:.2f}%)\")\n",
    "    print(f\"Correct Predictions: {correct_count} ({accuracy:.2f}%)\")\n",
    "    print(f\"Results saved to {output_csv}\")\n",
    "\n",
    "# مثال استفاده از کد\n",
    "input_folder = \"./combined_images\"  # پوشه تصاویر\n",
    "clean_folder = \"./output_clean\"  # پوشه تصاویر پاک\n",
    "stego_folder = \"./output_stego\"  # پوشه تصاویر آلوده\n",
    "output_csv = \"final_results.csv\"  # فایل خروجی\n",
    "process_folder(input_folder, clean_folder, stego_folder, output_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# روش یادگیری ماشین #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saleh\\AppData\\Local\\Temp\\ipykernel_17996\\3299838119.py:18: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  skewness = skew(lsb.flatten())\n",
      "C:\\Users\\Saleh\\AppData\\Local\\Temp\\ipykernel_17996\\3299838119.py:19: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  kurt = kurtosis(lsb.flatten())\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 99\u001b[0m\n\u001b[0;32m     96\u001b[0m stego_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./output_stego\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     97\u001b[0m output_csv \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_results.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 99\u001b[0m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstego_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_csv\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 65\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(clean_folder, stego_folder, output_csv)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_and_evaluate\u001b[39m(clean_folder, stego_folder, output_csv):\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreparing dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 65\u001b[0m     clean_data, clean_labels \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Label 0 for clean\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     stego_data, stego_labels \u001b[38;5;241m=\u001b[39m prepare_dataset(stego_folder, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Label 1 for stego\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# Combine data and labels\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[11], line 55\u001b[0m, in \u001b[0;36mprepare_dataset\u001b[1;34m(folder, label, block_size)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 55\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     data\u001b[38;5;241m.\u001b[39mappend(features)\n\u001b[0;32m     57\u001b[0m     labels\u001b[38;5;241m.\u001b[39mappend(label)\n",
      "Cell \u001b[1;32mIn[11], line 43\u001b[0m, in \u001b[0;36mprocess_image\u001b[1;34m(image_path, block_size)\u001b[0m\n\u001b[0;32m     41\u001b[0m lsb \u001b[38;5;241m=\u001b[39m extract_lsb(image)\n\u001b[0;32m     42\u001b[0m global_features \u001b[38;5;241m=\u001b[39m calculate_statistical_features(lsb)\n\u001b[1;32m---> 43\u001b[0m block_features \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_block_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlsb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(global_features) \u001b[38;5;241m+\u001b[39m block_features\n",
      "Cell \u001b[1;32mIn[11], line 33\u001b[0m, in \u001b[0;36mcalculate_block_features\u001b[1;34m(lsb, block_size)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m block\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     32\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m         features\u001b[38;5;241m.\u001b[39mextend(\u001b[43mcalculate_statistical_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m features\n",
      "Cell \u001b[1;32mIn[11], line 18\u001b[0m, in \u001b[0;36mcalculate_statistical_features\u001b[1;34m(lsb)\u001b[0m\n\u001b[0;32m     16\u001b[0m mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(lsb)\n\u001b[0;32m     17\u001b[0m std_dev \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstd(lsb)\n\u001b[1;32m---> 18\u001b[0m skewness \u001b[38;5;241m=\u001b[39m \u001b[43mskew\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlsb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m kurt \u001b[38;5;241m=\u001b[39m kurtosis(lsb\u001b[38;5;241m.\u001b[39mflatten())\n\u001b[0;32m     20\u001b[0m unique, counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lsb, return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Saleh\\.conda\\envs\\peak3NS\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:522\u001b[0m, in \u001b[0;36m_axis_nan_policy_factory.<locals>.axis_nan_policy_decorator.<locals>.axis_nan_policy_wrapper\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    520\u001b[0m     samples \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39masarray(sample\u001b[38;5;241m.\u001b[39mravel()) \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m samples]\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 522\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[43m_broadcast_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    523\u001b[0m     axis \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_1d(axis)\n\u001b[0;32m    524\u001b[0m     n_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(axis)\n",
      "File \u001b[1;32mc:\\Users\\Saleh\\.conda\\envs\\peak3NS\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:50\u001b[0m, in \u001b[0;36m_broadcast_arrays\u001b[1;34m(arrays, axis, xp)\u001b[0m\n\u001b[0;32m     48\u001b[0m arrays \u001b[38;5;241m=\u001b[39m [xp\u001b[38;5;241m.\u001b[39masarray(arr) \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m     49\u001b[0m shapes \u001b[38;5;241m=\u001b[39m [arr\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m---> 50\u001b[0m new_shapes \u001b[38;5;241m=\u001b[39m \u001b[43m_broadcast_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m     new_shapes \u001b[38;5;241m=\u001b[39m [new_shapes]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(arrays)\n",
      "File \u001b[1;32mc:\\Users\\Saleh\\.conda\\envs\\peak3NS\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:110\u001b[0m, in \u001b[0;36m_broadcast_shapes\u001b[1;34m(shapes, axis)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;66;03m# Add back the shape elements that were ignored\u001b[39;00m\n\u001b[0;32m    109\u001b[0m     new_axis \u001b[38;5;241m=\u001b[39m axis \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(axis))\n\u001b[1;32m--> 110\u001b[0m     new_shapes \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremoved_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m                  \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mremoved_shape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mremoved_shapes\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_shapes\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Saleh\\.conda\\envs\\peak3NS\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:110\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;66;03m# Add back the shape elements that were ignored\u001b[39;00m\n\u001b[0;32m    109\u001b[0m     new_axis \u001b[38;5;241m=\u001b[39m axis \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(axis))\n\u001b[1;32m--> 110\u001b[0m     new_shapes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremoved_shape\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    111\u001b[0m                   \u001b[38;5;28;01mfor\u001b[39;00m removed_shape \u001b[38;5;129;01min\u001b[39;00m removed_shapes]\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_shapes\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Saleh\\.conda\\envs\\peak3NS\\Lib\\site-packages\\numpy\\lib\\function_base.py:5526\u001b[0m, in \u001b[0;36minsert\u001b[1;34m(arr, obj, values, axis)\u001b[0m\n\u001b[0;32m   5524\u001b[0m slobj[axis] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(index, index\u001b[38;5;241m+\u001b[39mnumnew)\n\u001b[0;32m   5525\u001b[0m new[\u001b[38;5;28mtuple\u001b[39m(slobj)] \u001b[38;5;241m=\u001b[39m values\n\u001b[1;32m-> 5526\u001b[0m slobj[axis] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mslice\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mnumnew\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   5527\u001b[0m slobj2 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)] \u001b[38;5;241m*\u001b[39m ndim\n\u001b[0;32m   5528\u001b[0m slobj2[axis] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(index, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import csv\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Function to extract LSB\n",
    "def extract_lsb(image):\n",
    "    return image & 1\n",
    "\n",
    "# Function to calculate statistical features for the entire image\n",
    "def calculate_statistical_features(lsb):\n",
    "    mean = np.mean(lsb)\n",
    "    std_dev = np.std(lsb)\n",
    "    skewness = skew(lsb.flatten())\n",
    "    kurt = kurtosis(lsb.flatten())\n",
    "    unique, counts = np.unique(lsb, return_counts=True)\n",
    "    bit_balance = counts[0] / (counts[1] + 1e-9) if len(counts) > 1 else 1.0\n",
    "    return mean, std_dev, skewness, kurt, bit_balance\n",
    "\n",
    "# Function to calculate block-wise features\n",
    "def calculate_block_features(lsb, block_size=6):\n",
    "    h, w = lsb.shape\n",
    "    features = []\n",
    "    for i in range(0, h, block_size):\n",
    "        for j in range(0, w, block_size):\n",
    "            block = lsb[i:i+block_size, j:j+block_size]\n",
    "            if block.size == 0:\n",
    "                continue\n",
    "            features.extend(calculate_statistical_features(block))\n",
    "    return features\n",
    "\n",
    "# Function to process a single image\n",
    "def process_image(image_path, block_size=6):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Unable to read image: {image_path}\")\n",
    "    lsb = extract_lsb(image)\n",
    "    global_features = calculate_statistical_features(lsb)\n",
    "    block_features = calculate_block_features(lsb, block_size)\n",
    "    return list(global_features) + block_features\n",
    "\n",
    "# Function to prepare dataset\n",
    "def prepare_dataset(folder, label, block_size=6):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        image_path = os.path.join(folder, filename)\n",
    "        if not os.path.isfile(image_path):\n",
    "            continue\n",
    "        try:\n",
    "            features = process_image(image_path, block_size)\n",
    "            data.append(features)\n",
    "            labels.append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "    return data, labels\n",
    "\n",
    "# Main function to train and evaluate\n",
    "def train_and_evaluate(clean_folder, stego_folder, output_csv):\n",
    "    print(\"Preparing dataset...\")\n",
    "    clean_data, clean_labels = prepare_dataset(clean_folder, 0)  # Label 0 for clean\n",
    "    stego_data, stego_labels = prepare_dataset(stego_folder, 1)  # Label 1 for stego\n",
    "\n",
    "    # Combine data and labels\n",
    "    X = np.array(clean_data + stego_data)\n",
    "    y = np.array(clean_labels + stego_labels)\n",
    "\n",
    "    # Split dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Train model\n",
    "    print(\"Training Gradient Boosting Classifier...\")\n",
    "    model = GradientBoostingClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate model\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"\\nModel Evaluation:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Save results to CSV\n",
    "    results = zip(y_test, y_pred)\n",
    "    with open(output_csv, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"True Label\", \"Predicted Label\"])\n",
    "        writer.writerows(results)\n",
    "\n",
    "    print(f\"Results saved to {output_csv}\")\n",
    "\n",
    "# Folders for clean and stego images\n",
    "clean_folder = \"./output_clean\"\n",
    "stego_folder = \"./output_stego\"\n",
    "output_csv = \"final_results.csv\"\n",
    "\n",
    "train_and_evaluate(clean_folder, stego_folder, output_csv)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peak3NS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
